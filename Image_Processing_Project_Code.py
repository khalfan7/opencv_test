# -*- coding: utf-8 -*-
"""Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fMcCHtb0JybQLJfWJRiWL-tjFnrRHdgd

# Student Name: HUMAID ALMANSOORI
# Student ID: 1101473


# Student Name: ABDALLA HABLEEL
# Student ID: 1097830
"""

# Mounting Drive for file upload
"""**We mounted google drive so that we can upload images directly from our drive and start working on it.**"""

# Importing Required Libraries
import cv2
import numpy as np


def resize_img(img):
    # Desired width
    new_width = 400

    # Calculating new height to maintain aspect ratio
    height, width = img.shape[:2]
    new_height = int((new_width / width) * height)

    # Resizing image
    small_img = cv2.resize(img, (new_width, new_height))
    return small_img

"""**As the input image is quite high resolution so we have to resize it to show it effeciently. Also we have to take care of the ratio so that our image doesn't look wierd or streched**"""

img = cv2.imread("/home/argonghost/Downloads/pic_for_project.jpg")

# Resizing Image while maintaining ratio as original image is quite large
small_img = resize_img(img)

# Displaying image


def pencil_sketch(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    inv = 255 - gray
    blur = cv2.GaussianBlur(inv, (21, 21), 0)
    sketch = cv2.divide(gray, 255 - blur, scale=256)
    return sketch

pencil_img = pencil_sketch(img)

# Resizing Image while maintaining ratio as original image is quite large
small_img = resize_img(pencil_img)

# Displaying image


"""**This code is used to convert an image into a pencil sketch effect. First it converts the image to grayscale image and then it inverts the grayscale image which is bascially inversion of that image. Then a Gaussian blur is applied to the inverted image and the final sketch is created by dividing the grayscale image by the inverted blur.**"""

def cartoon_effect(img):
    input_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    input_img = cv2.medianBlur(input_img, 7)

    # Extracting the Edges
    edges = cv2.adaptiveThreshold(input_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                          cv2.THRESH_BINARY, 7, 8)

    # Smoothing the color
    smoothness = cv2.bilateralFilter(img, 9, 250, 250)

    # Combining both parts
    cartoon = cv2.bitwise_and(smoothness, smoothness, mask=edges)
    return cartoon

cartoon_img = cartoon_effect(img)

# Resizing Image while maintaining ratio as original image is quite large
small_img = resize_img(cartoon_img)

# Displaying image


"""**This code applies a cartoon effect to an image. First, it converts the image to grayscale and applies a median blur to reduce noise. Then, it extracts the edges of the image using adaptive thresholding. To smooth the image colors, it applies a bilateral filter. Finally, the cartoon effect is created by combining the smoothed image with the edges using a bitwise AND operation.**"""

def warming_filter(img):
    img = img.astype(np.float32)
    # Increasing reds and then reducing blues
    img[..., 2] = np.clip(img[..., 2] * 1.4, 0, 255)  # Red channel
    img[..., 0] = np.clip(img[..., 0] * 0.9, 0, 255)  # Blue channel
    return img.astype(np.uint8)

warm_img = warming_filter(img)

# Resizing Image while maintaining ratio as original image is quite large
small_img = resize_img(warm_img)

# Displaying image


"""**This code applies the required warming filter to the above image by enhancing the red tones and reducing the blue tones. First it converts the image to a floating-point format so that we can have better manipulation of pixels in the image. The red channel is increased by multiplying its values by 1.4, while the blue channel is decreased by multiplying it by 0.9. Then the image is clipped to ensure pixel values remain within the valid range (0 to 255) and then it is converted back to an unsigned 8-bit format.**"""

def cooling_filter(img):
    img = img.astype(np.float32)
    # Increasing blues and then reducing reds
    img[..., 0] = np.clip(img[..., 0] * 1.4, 0, 255)  # Blue channel
    img[..., 2] = np.clip(img[..., 2] * 0.7, 0, 255)  # Red channel
    return img.astype(np.uint8)

cool_img = cooling_filter(img)

# Resizing Image while maintaining ratio as original image is quite large
small_img = resize_img(cool_img)

# Displaying image


"""**This code applies the required cooling filter to the above image by enhancing the blue tones and reducing the red tones. First it converts the image to a floating-point format so that we can have better manipulation of pixels in the image. The blue channel is increased by multiplying its values by 1.4, while the blue channel is decreased by multiplying it by 0.7. Then the image is clipped to ensure pixel values remain within the valid range (0 to 255) and then it is converted back to an unsigned 8-bit format.**"""

def hdr_effect(img):
    # Simple HDR-like effect by tone mapping and increasing contrast
    img_hdr = cv2.detailEnhance(img, sigma_s=12, sigma_r=0.15)
    img_hdr = cv2.edgePreservingFilter(img_hdr, flags=1, sigma_s=60, sigma_r=0.4)
    return img_hdr

hdr_img = hdr_effect(img)

# Resizing Image while maintaining ratio as original image is quite large
small_img = resize_img(hdr_img)

# Displaying image


"""**This code applies the required HDR effect to the above image by enhancing details and increasing the contrast of the image. In the above code we are first enhancing the fine details and simulating HDR-like qualities. Then we are further preserving edges and reducing noise while enhancing contrast. The result is an image with enhanced details and a more vivid appearance.**"""

def glitch_aberration_filter(img):
    # Simulating RGB split glitch effect
    b, g, r = cv2.split(img)
    rows, cols = b.shape
    # Shifting channels by a few pixels
    r_shifted = np.roll(r, 10, axis=1)
    g_shifted = np.roll(g, -7, axis=0)
    b_shifted = np.roll(b, 5, axis=0)
    glitch = cv2.merge([b_shifted, g_shifted, r_shifted])
    return glitch

glitch_img = glitch_aberration_filter(img)

# Resizing Image while maintaining ratio as original image is quite large
small_img = resize_img(glitch_img)

# Displaying image




"""**This code is simulating a glitch aberration effect by shifting the RGB color channels of the image. It is first splitting the image into its blue, green and red channels. Then we are shifting each channel by few pixels along different axes. Finally the channels are merged back together which rsults in glitchy RGB split effect that simulates digital distortion.**"""

def watercolor_filter(img):
    # Apply repeated bilateral filtering for smooth color transitions
    smoothed = img.copy()
    for _ in range(3):
        smoothed = cv2.bilateralFilter(smoothed, d=9, sigmaColor=100, sigmaSpace=100)

    # Create edges
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 80, 150)
    edges = cv2.dilate(edges, None, iterations=1)
    edges_inv = cv2.bitwise_not(edges)
    edges_inv = cv2.cvtColor(edges_inv, cv2.COLOR_GRAY2BGR)

    # Combine: darken edges on smoothed image
    watercolor = (smoothed.astype(np.float32) * (edges_inv.astype(np.float32) / 255.0)).astype(np.uint8)
    return watercolor

wc_img = watercolor_filter(img)

"""**This code is generating a water color effect through smoothing colors using bilateral filtering, edges are detected and inverted and then the smoothened image and detected edges are combined and displayed**"""

def duotone_filter(img, color1=(30, 10, 100), color2=(230, 220, 100)):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0
    duotone = np.zeros_like(img, dtype=np.float32)
    for i in range(3):
        duotone[:, :, i] = color1[i] * (1 - gray) + color2[i] * gray
    return np.clip(duotone, 0, 255).astype(np.uint8)


duo_img = duotone_filter(img)


"""**This code produces a duo tone effect by conversion of Gray scale and then an empty image is prepared to store the results, and blending between the colors is performed**"""

def halftone_filter(img, dot_size=6):

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    halftone = np.ones((h, w), dtype=np.uint8) * 255  # white canvas
    for y in range(0, h, dot_size):
        for x in range(0, w, dot_size):
            patch = gray[y:y+dot_size, x:x+dot_size]
            intensity = np.mean(patch)
            radius = int((1 - intensity / 255) * (dot_size / 2))
            cv2.circle(halftone, (x + dot_size//2, y + dot_size//2), radius, 0, -1)
    halftone_bgr = cv2.cvtColor(halftone, cv2.COLOR_GRAY2BGR)
    return halftone_bgr

half_img = halftone_filter(img)


"""**This function produces a halftone effect, first the gray scale conversion is performed, an output canvas is prepared, after which looping over the image is done in small blocks, brightness of each patch is measured, and dot size is measured based on the brightness, after which the dot is drawn and image is converted back to color after which the picture is displayed with half tone filter **"""

def infrared_filter(img):
    b, g, r = cv2.split(img)

    # Increase red, reduce blue
    r_boost = cv2.add(r, 60)
    g_adj = cv2.addWeighted(g, 0.7, r, 0.3, 0)
    b_suppressed = cv2.subtract(r, g)
    b_suppressed = cv2.normalize(b_suppressed, None, 0, 255, cv2.NORM_MINMAX)

    # Merge and apply contrast stretch
    ir = cv2.merge([b_suppressed, g_adj, r_boost])
    ir = cv2.convertScaleAbs(ir, alpha=1.3, beta=10)
    return ir


ir_img = infrared_filter(img)


"""**This function produces the warm effect. First, image is split into RGB (Red-Green-Blue) channels, and the red channel is boosted, while the green channel is adjusted and the blue channel is suppressed. Channels are emerged back, contrast is enhanced, and the results are displayed. **"""
print("Successfully ran")